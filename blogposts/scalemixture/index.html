<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/bayesiantribulations/libs/katex/katex.min.css"> <link rel=stylesheet  href="/bayesiantribulations/libs/highlight/github.min.css"> <link rel=stylesheet  href="/bayesiantribulations/css/franklin.css"> <link rel=stylesheet  href="/bayesiantribulations/css/poole_hyde.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/bayesiantribulations/assets/favicon.png"> <title>Automatic Conditional Conjugacy for Gaussian Processes</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <h1><a href="/bayesiantribulations/">Bayesian Tribulations</a></h1> <p class=lead >Unexpected computational events!</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/bayesiantribulations/">Home</a> <a class="sidebar-nav-item active" href="/bayesiantribulations/blogposts/">Blog Posts</a> <a class="sidebar-nav-item " href="/bayesiantribulations/publications/">Publications</a> </nav> <p>&copy; Théo Galy-Fajou.</p> </div> </div> <div class="content container"> <div class=franklin-content ><h1 id=automatic_conditional_conjugacy_for_gaussian_processes ><a href="#automatic_conditional_conjugacy_for_gaussian_processes" class=header-anchor >Automatic Conditional Conjugacy for Gaussian Processes</a></h1> <p>Last summer our paper <a href="https://arxiv.org/abs/2002.11451">&quot;Automated Augmented Conjugate Inference for Non-conjugate Gaussian Process Models&quot;</a> written with Florian Wenzel and Manfred Opper &#40;my supervisor&#41; got accepted at AISTATS 2020. This is a paper I am particularly proud of, as it contains both a beautiful theory and a direct application. Although you can find the video of the presentation here, I thought I would write a small blog post to give a light approach to it.</p> <div id=presentation-embed-38930226 ></div> <script src='https://slideslive.com/embed_presentation.js'></script> <script> embed = new SlidesLiveEmbed('presentation-embed-38930226', { presentationId: '38930226', autoPlay: false, // change to true to autoplay the embedded presentation verticalEnabled: true }); </script> <h2 id=the_problem ><a href="#the_problem" class=header-anchor >The problem</a></h2> <p>Over the past years, my research has been focused on how to modify likelihood functions to make them nicer to work with when you have a Gaussian prior. Mostly, I worked with previous work which found a correspondence between for example the logistic likelihood and the Polya-Gamma variable.</p> <p>Let&#39;s give a simple example. You should be familiar with the logistic function:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mo stretchy=false >(</mo><mi>f</mi><mo stretchy=false >)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy=false >(</mo><mo>−</mo><mi>x</mi><mo stretchy=false >)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(f) = \frac{1}{1+\exp(-x)}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.25744em;vertical-align:-0.936em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mop >exp</span><span class=mopen >(</span><span class=mord >−</span><span class="mord mathdefault">x</span><span class=mclose >)</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span> <pre><code class="julia hljs">σ(f) = inv(<span class=hljs-number >1</span> + exp(-f))</code></pre>
<p> <p><span style="color:red;">// Image matching '/assets/blogposts/scalemixture/logistic.svg' not found. //</span></p></p>
<p>It is heavily used for binary classification, since <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mo stretchy=false >(</mo><mi>f</mi><mo stretchy=false >)</mo><mo>∈</mo><mo stretchy=false >[</mo><mn>0</mn><mo separator=true >,</mo><mn>1</mn><mo stretchy=false >]</mo></mrow><annotation encoding="application/x-tex">\sigma(f)\in [0, 1]</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >[</span><span class=mord >0</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >1</span><span class=mclose >]</span></span></span></span>, for example for Gaussian Process classification, one can use <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy=false >(</mo><msub><mi>y</mi><mi>i</mi></msub><mi mathvariant=normal >∣</mi><msub><mi>f</mi><mi>i</mi></msub><mo stretchy=false >)</mo><mo>=</mo><mtext>Bernoulli</mtext><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >∣</mi><mi>σ</mi><mo stretchy=false >(</mo><msub><mi>f</mi><mi>i</mi></msub><mo stretchy=false >)</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p(y_i|f_i) = \text{Bernoulli}(y|\sigma(f_i))</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class=mopen >(</span><span class=mord ><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mord >∣</span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >Bernoulli</span></span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=mord >∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class=mopen >(</span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span><span class=mclose >)</span></span></span></span>.</p>
<p>The problem with such a link is that working with Gaussian priors &#40;as in Gaussian Processes&#41; makes the posterior untractable.</p>
<p>The different solution are Variational Inference &#40;VI&#41;, where one look for the closest distribution <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>f</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">q(f)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mclose >)</span></span></span></span> to the true posterior <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy=false >(</mo><mi>f</mi><mi mathvariant=normal >∣</mi><mi>y</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p(f|y)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mord >∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span> by minimizing the KL divergence, sampling and others.</p>
<p>The problem with VI is that one needs to compute the expectation of the log-likelihood <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant=double-struck >E</mi><mrow><mi>q</mi><mo stretchy=false >(</mo><mi>f</mi><mo stretchy=false >)</mo></mrow></msub><mrow><mo fence=true >[</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy=false >(</mo><mi>y</mi><mi mathvariant=normal >∣</mi><mi>f</mi><mo stretchy=false >)</mo><mo fence=true >]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbb{E}_{ q(f)}\left[ \log p(y|f) \right]</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class=mord ><span class=mord ><span class="mord mathbb">E</span></span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;">[</span><span class=mop >lo<span style="margin-right:0.01389em;">g</span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">p</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=mord >∣</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mclose >)</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span> and get its gradient given the variational parameters. Often this integral is intractable as well. One can use quadrature, sampling and other approaches, but they can turn out expensive and/or inaccurate.</p>
<p>What we propose is to rewrite the likelihood into a form where the integral becomes analytically tractable.</p>
<h2 id=scale_mixture_of_gaussians ><a href="#scale_mixture_of_gaussians" class=header-anchor >Scale Mixture of Gaussians</a></h2>
<p>Let&#39;s introduce a family of functions called scale mixtures of Gaussians. These can be written as :</p>
<span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mo>∝</mo><msubsup><mo>∫</mo><mn>0</mn><mi mathvariant=normal >∞</mi></msubsup><mi mathvariant=script >N</mi><mo stretchy=false >(</mo><mn>0</mn><mo separator=true >,</mo><mi>ω</mi><mo stretchy=false >)</mo><mi>p</mi><mo stretchy=false >(</mo><mi>ω</mi><mo stretchy=false >)</mo><mi>d</mi><mi>ω</mi><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex">f(x) \propto \int_0^\infty\mathcal{N}(0, \omega)p(\omega)d\omega.</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mopen >(</span><span class="mord mathdefault">x</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∝</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.326242em;vertical-align:-0.9119499999999999em;"></span><span class=mop ><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.414292em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∞</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class=mopen >(</span><span class=mord >0</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class=mclose >)</span><span class="mord mathdefault">p</span><span class=mopen >(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class=mclose >)</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class=mord >.</span></span></span></span></span>
<p>You can imagine it as being an infinite weighted sum of Gaussians with different variance <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span></span></span></span>. A well known example is for instance the Student-T likelihood :</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> Distributions
nu = <span class=hljs-number >2.0</span>
studentt = TDist(nu)
pomega = InverseGamma(nu, nu)
plot(-<span class=hljs-number >5</span>:<span class=hljs-number >0.01</span>:<span class=hljs-number >5</span>, x-&gt;pdf(studentt, x), label=<span class=hljs-string >&quot;Student-T&quot;</span>)

plot!()</code></pre>
<div class=page-foot >
  <div class=copyright >
    &copy; Théo Galy-Fajou. Last modified: April 28, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div>


    </div>  

    
        



    
    
        


    

    
        <script src="https://utteranc.es/client.js" repo="theogf/bayesiantribulations"
            issue-term=title  label="[Comments]" theme=github-light  crossorigin=anonymous 
            async>
        </script>